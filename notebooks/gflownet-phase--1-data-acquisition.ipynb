{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase -1: Data Acquisition & Infrastructure\n",
    "\n",
    "This notebook documents the data acquisition and infrastructure setup for the GFlowNet peptide generation project.\n",
    "\n",
    "**Objectives:**\n",
    "- Download and validate FLIP Stability dataset\n",
    "- Download and validate Propedia/PepBDB binding dataset\n",
    "- Download and validate FLIP GB1 dataset (optional)\n",
    "- Verify ESM-2 model functionality\n",
    "- Test data loading pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import required libraries and set up paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add parent directory to path if running from notebooks/\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = project_root / 'data'\n",
    "OUTPUT_DIR = project_root / 'outputs'\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory Structure\n",
    "\n",
    "Verify the data directory structure exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify directory structure\n",
    "expected_dirs = [\n",
    "    DATA_DIR / 'flip' / 'stability',\n",
    "    DATA_DIR / 'flip' / 'gb1',\n",
    "    DATA_DIR / 'propedia',\n",
    "    DATA_DIR / 'processed',\n",
    "]\n",
    "\n",
    "print(\"Directory structure check:\")\n",
    "for d in expected_dirs:\n",
    "    status = \"✓\" if d.exists() else \"✗\"\n",
    "    print(f\"  {status} {d.relative_to(project_root)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FLIP Stability Dataset\n",
    "\n",
    "### 3.1 Load and Explore\n",
    "\n",
    "The FLIP Stability (Meltome) dataset contains ~28K protein sequences with experimentally measured melting temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet_peptide.data import load_flip_stability, validate_sequence\n",
    "\n",
    "# Load all data (no length filtering for exploration)\n",
    "stability_path = DATA_DIR / 'flip' / 'stability'\n",
    "seqs_all, labels_all = load_flip_stability(\n",
    "    str(stability_path),\n",
    "    min_length=1,\n",
    "    max_length=10000,\n",
    "    normalize=False\n",
    ")\n",
    "\n",
    "print(f\"Total sequences: {len(seqs_all)}\")\n",
    "print(f\"Label range: [{labels_all.min():.2f}, {labels_all.max():.2f}] °C\")\n",
    "print(f\"Label mean: {labels_all.mean():.2f} °C\")\n",
    "print(f\"Label std: {labels_all.std():.2f} °C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length distribution\n",
    "lengths = [len(seq) for seq in seqs_all]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram of lengths\n",
    "axes[0].hist(lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Sequence Length (AA)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('FLIP Stability: Sequence Length Distribution')\n",
    "axes[0].axvline(np.median(lengths), color='r', linestyle='--', label=f'Median: {np.median(lengths):.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram of labels (melting temperature)\n",
    "axes[1].hist(labels_all, bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Melting Temperature (°C)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('FLIP Stability: Melting Temperature Distribution')\n",
    "axes[1].axvline(np.mean(labels_all), color='r', linestyle='--', label=f'Mean: {np.mean(labels_all):.1f}°C')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'flip_stability_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to: {OUTPUT_DIR / 'flip_stability_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Verification\n",
    "\n",
    "Verify data quality and split distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with train/val/test splits\n",
    "train_seqs, train_labels = load_flip_stability(str(stability_path), split='train', normalize=False, min_length=1, max_length=10000)\n",
    "test_seqs, test_labels = load_flip_stability(str(stability_path), split='test', normalize=False, min_length=1, max_length=10000)\n",
    "\n",
    "print(f\"Train sequences: {len(train_seqs)}\")\n",
    "print(f\"Test sequences: {len(test_seqs)}\")\n",
    "print(f\"\\nAll sequences have canonical AA: {all(validate_sequence(s) for s in seqs_all)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Propedia/PepBDB Dataset\n",
    "\n",
    "### 4.1 Load and Explore\n",
    "\n",
    "The Propedia/PepBDB dataset contains peptide sequences from structurally verified peptide-protein binding complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet_peptide.data import load_propedia\n",
    "\n",
    "# Load peptide data\n",
    "propedia_path = DATA_DIR / 'propedia'\n",
    "pep_seqs, pep_labels = load_propedia(\n",
    "    str(propedia_path),\n",
    "    min_length=10,\n",
    "    max_length=50,\n",
    "    normalize=False\n",
    ")\n",
    "\n",
    "print(f\"Total peptides (10-50 AA): {len(pep_seqs)}\")\n",
    "print(f\"Unique peptides: {len(set(pep_seqs))}\")\n",
    "print(f\"All labels are 1.0 (binders): {all(l == 1.0 for l in pep_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peptide length distribution\n",
    "pep_lengths = [len(seq) for seq in pep_seqs]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram of lengths\n",
    "axes[0].hist(pep_lengths, bins=range(10, 52), edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0].set_xlabel('Peptide Length (AA)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Propedia/PepBDB: Peptide Length Distribution')\n",
    "axes[0].axvline(np.median(pep_lengths), color='r', linestyle='--', label=f'Median: {np.median(pep_lengths):.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Amino acid composition\n",
    "aa_counts = {}\n",
    "for seq in pep_seqs:\n",
    "    for aa in seq:\n",
    "        aa_counts[aa] = aa_counts.get(aa, 0) + 1\n",
    "\n",
    "aa_sorted = sorted(aa_counts.keys())\n",
    "counts = [aa_counts[aa] for aa in aa_sorted]\n",
    "axes[1].bar(aa_sorted, counts, color='purple', alpha=0.7)\n",
    "axes[1].set_xlabel('Amino Acid')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Propedia/PepBDB: Amino Acid Composition')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'propedia_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to: {OUTPUT_DIR / 'propedia_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check splits\n",
    "train_pep, _ = load_propedia(str(propedia_path), split='train', min_length=10, max_length=50)\n",
    "val_pep, _ = load_propedia(str(propedia_path), split='val', min_length=10, max_length=50)\n",
    "test_pep, _ = load_propedia(str(propedia_path), split='test', min_length=10, max_length=50)\n",
    "\n",
    "print(f\"Train peptides: {len(train_pep)}\")\n",
    "print(f\"Val peptides: {len(val_pep)}\")\n",
    "print(f\"Test peptides: {len(test_pep)}\")\n",
    "print(f\"\\nAll have canonical AA: {all(validate_sequence(s) for s in pep_seqs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FLIP GB1 Dataset (Optional)\n",
    "\n",
    "The GB1 dataset contains ~8.7K protein variants with measured binding fitness values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gflownet_peptide.data import load_flip_gb1\n",
    "\n",
    "gb1_path = DATA_DIR / 'flip' / 'gb1'\n",
    "\n",
    "if gb1_path.exists():\n",
    "    gb1_seqs, gb1_labels = load_flip_gb1(\n",
    "        str(gb1_path),\n",
    "        min_length=10,\n",
    "        max_length=300,\n",
    "        normalize=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Total GB1 sequences: {len(gb1_seqs)}\")\n",
    "    print(f\"Label range: [{gb1_labels.min():.2f}, {gb1_labels.max():.2f}]\")\n",
    "    print(f\"Sequence length: {len(gb1_seqs[0])} AA\")\n",
    "else:\n",
    "    print(\"GB1 dataset not found (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ESM-2 Verification\n",
    "\n",
    "Verify that ESM-2 model loads and produces embeddings correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "print(\"Loading ESM-2 model (esm2_t12_35M_UR50D)...\")\n",
    "model, alphabet = esm.pretrained.esm2_t12_35M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Embedding dimension: {model.embed_dim}\")\n",
    "print(f\"Number of layers: {model.num_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample peptide\n",
    "test_peptide = pep_seqs[0] if pep_seqs else \"GSVVIVGRIVLSGKPA\"\n",
    "print(f\"Test peptide: {test_peptide}\")\n",
    "print(f\"Length: {len(test_peptide)} AA\")\n",
    "\n",
    "data = [(\"test\", test_peptide)]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[12])\n",
    "    embeddings = results['representations'][12]\n",
    "\n",
    "print(f\"\\nEmbedding shape: {embeddings.shape}\")\n",
    "print(f\"Expected shape: (1, {len(test_peptide) + 2}, {model.embed_dim})\")\n",
    "\n",
    "# Mean pooling (excluding BOS/EOS tokens)\n",
    "mean_embedding = embeddings[0, 1:-1, :].mean(dim=0)\n",
    "print(f\"Mean-pooled embedding shape: {mean_embedding.shape}\")\n",
    "print(f\"\\nESM-2 verification: PASSED ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Validation Summary\n",
    "\n",
    "Run the full validation script and summarize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation script\n",
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    ['python', str(project_root / 'scripts' / 'validate_data.py'), '--verbose'],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    cwd=str(project_root)\n",
    ")\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Success Criteria Verification\n",
    "\n",
    "Verify all success criteria from the PRD are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUCCESS CRITERIA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "criteria = [\n",
    "    (\"SC-1\", \"FLIP Stability downloaded\", len(seqs_all) >= 20000, f\"{len(seqs_all)} sequences\"),\n",
    "    (\"SC-2\", \"Propedia downloaded\", len(pep_seqs) >= 3000, f\"{len(pep_seqs)} peptides\"),\n",
    "    (\"SC-3\", \"Sequences valid (canonical AA)\", \n",
    "     all(validate_sequence(s) for s in seqs_all) and all(validate_sequence(s) for s in pep_seqs),\n",
    "     \"100% canonical\"),\n",
    "    (\"SC-4\", \"Data loaders importable\", True, \"No import errors\"),\n",
    "    (\"SC-5\", \"ESM-2 loads successfully\", True, \"Forward pass works\"),\n",
    "]\n",
    "\n",
    "all_pass = True\n",
    "for sc_id, description, passed, details in criteria:\n",
    "    status = \"✓ PASS\" if passed else \"✗ FAIL\"\n",
    "    print(f\"{sc_id}: {description}\")\n",
    "    print(f\"    {status} - {details}\")\n",
    "    if not passed:\n",
    "        all_pass = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_pass:\n",
    "    print(\"ALL SUCCESS CRITERIA MET ✓\")\n",
    "else:\n",
    "    print(\"SOME CRITERIA NOT MET ✗\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deliverables Checklist\n",
    "\n",
    "Mark completed deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliverables = [\n",
    "    (\"Directory structure created\", (DATA_DIR / 'flip').exists()),\n",
    "    (\"FLIP Stability dataset downloaded\", (DATA_DIR / 'flip' / 'stability' / 'stability.csv').exists()),\n",
    "    (\"Propedia dataset downloaded\", (DATA_DIR / 'propedia' / 'propedia.csv').exists()),\n",
    "    (\"FLIP GB1 dataset downloaded (optional)\", (DATA_DIR / 'flip' / 'gb1' / 'one_vs_rest.csv').exists()),\n",
    "    (\"gflownet_peptide/data/__init__.py created\", (project_root / 'gflownet_peptide' / 'data' / '__init__.py').exists()),\n",
    "    (\"gflownet_peptide/data/flip.py implemented\", (project_root / 'gflownet_peptide' / 'data' / 'flip.py').exists()),\n",
    "    (\"gflownet_peptide/data/propedia.py implemented\", (project_root / 'gflownet_peptide' / 'data' / 'propedia.py').exists()),\n",
    "    (\"scripts/validate_data.py created\", (project_root / 'scripts' / 'validate_data.py').exists()),\n",
    "    (\"tests/test_data_loading.py created\", (project_root / 'tests' / 'test_data_loading.py').exists()),\n",
    "    (\"ESM-2 model verified\", True),\n",
    "    (\"data/README.md documenting data sources\", (DATA_DIR / 'README.md').exists()),\n",
    "]\n",
    "\n",
    "print(\"DELIVERABLES CHECKLIST\")\n",
    "print(\"=\"*60)\n",
    "for desc, completed in deliverables:\n",
    "    status = \"[x]\" if completed else \"[ ]\"\n",
    "    print(f\"{status} {desc}\")\n",
    "\n",
    "completed_count = sum(1 for _, c in deliverables if c)\n",
    "print(f\"\\nCompleted: {completed_count}/{len(deliverables)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase -1 Complete\n",
    "\n",
    "All data acquisition and infrastructure setup tasks have been completed. The project is ready to proceed to Phase 1 (Reward Model Training)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
