# GFlowNet Peptide - Session TODO

**Created**: 2025-12-27 14:00 JST
**Last Updated**: 2025-12-27 14:00 JST
**Previous TODO**: [TODO-2025-12-26-1600.md](./TODO-2025-12-26-1600.md)

---

## Current Phase: Phase 3b - Training Stability Improvements

**Objective**: Address critical training instabilities discovered during the GFlowNet reward comparison experiments (Dec 26, 2025). Implement checkpoint selection by reward, entropy regularization, and switch to Sub-Trajectory Balance loss.

**PRD**: [docs/prd-phase-3b-training-stability.md](./prd-phase-3b-training-stability.md)
**Analysis**: [docs/Lesson-Learned-Reward-Function-Failures-2025-12-26-2030.md](./Lesson-Learned-Reward-Function-Failures-2025-12-26-2030.md)

---

## W&B Run History

| ID       | Name                           | State    | Created    | Notes |
|----------|--------------------------------|----------|------------|-------|
| 8rflp7l6 | gflownet-baseline-10k          | finished | 2025-12-26 | Flat rewards (untrained MLP heads) |
| zcb95gyl | gflownet-reward-C-improved-10k | finished | 2025-12-26 | **Best** - diverse samples, loss exploded |
| 3fr3yzn0 | gflownet-reward-B-esm2pll-10k  | finished | 2025-12-26 | Mode collapse to "MMM..." |
| 6qsqq6wz | gflownet-reward-A-trained-10k  | finished | 2025-12-26 | Diverse but low reward |
| -------- | ------------------------------ | -------- | ---------- | ----- |
| ???????? | phase3b-stb-validation-10k     | pending  | 2025-12-27 | STB + entropy 0.01 |
| ???????? | phase3b-entropy-0.00-10k       | pending  | 2025-12-27 | STB + no entropy |
| ???????? | phase3b-entropy-0.05-10k       | pending  | 2025-12-27 | STB + entropy 0.05 |
| ???????? | phase3b-entropy-0.10-10k       | pending  | 2025-12-27 | STB + entropy 0.10 |
| ???????? | phase3b-tb-baseline-10k        | pending  | 2025-12-27 | TB comparison |
| ???????? | phase3b-stb-logz10x-10k        | pending  | 2025-12-27 | log_Z LR 10x |

---

## Phase 3b Experiment Plan (6 Runs)

| # | Run Name | loss_type | entropy | log_z_lr | Purpose |
|---|----------|-----------|---------|----------|---------|
| 1 | `phase3b-stb-validation-10k` | STB | 0.01 | 3.0 | Main validation |
| 2 | `phase3b-entropy-0.00-10k` | STB | 0.00 | 3.0 | No entropy baseline |
| 3 | `phase3b-entropy-0.05-10k` | STB | 0.05 | 3.0 | Medium entropy |
| 4 | `phase3b-entropy-0.10-10k` | STB | 0.10 | 3.0 | Strong entropy |
| 5 | `phase3b-tb-baseline-10k` | TB | 0.01 | 3.0 | TB vs STB comparison |
| 6 | `phase3b-stb-logz10x-10k` | STB | 0.01 | 10.0 | log_Z LR comparison |

**Expected Runtime**: ~18 hours total (~3 hours per run × 6 runs)

---

## Completed This Session

### Code Development (Phase 3b Implementation)

- [x] **Fix checkpoint selection** - Select best model by reward, not loss
  - Added `best_reward` tracking in `trainer.py`
  - Changed checkpoint selection from `loss < best_loss` to `mean_reward > best_reward`
  - Backward compatible with old checkpoints

- [x] **Add entropy regularization** - Prevent policy overconfidence
  - Added `entropy_weight` parameter to `TrajectoryBalanceLoss`
  - Added `entropy_weight` parameter to `SubTrajectoryBalanceLoss`
  - Formula: `L_total = L_TB - entropy_weight * mean(log_P_F)`

- [x] **Update Trainer** - Pass entropy_weight parameter
  - Added `entropy_weight` to constructor
  - Stores in config for checkpointing

- [x] **CLI improvements** - New flags for stability parameters
  - `--entropy_weight` (default: from config or 0.0)
  - `--log_z_lr_multiplier` (default: from config or 10.0)
  - `--loss_type` (trajectory_balance or sub_trajectory_balance)

- [x] **Configuration updates** - Stable default hyperparameters
  - Changed `loss_type` from `trajectory_balance` to `sub_trajectory_balance`
  - Changed `log_z_lr_multiplier` from 10.0 to 3.0
  - Added `entropy_weight: 0.01`
  - Added `lambda_sub: 0.9`

- [x] **Test coverage** - New tests for all fixes
  - 4 tests for `TestCheckpointSelectionByReward`
  - 8 tests for `TestEntropyRegularization`
  - All 47 trainer/loss tests passing

### Tests

- All 134/135 tests passing (1 pre-existing flaky integration test)
- New tests: 12 tests added for Phase 3b features

---

## Phase 3b Command Execution Checklist

### Step 0: Verify Implementation ✅ COMPLETED

```bash
# Run new tests
pytest tests/test_loss.py::TestEntropyRegularization tests/test_trainer.py::TestCheckpointSelectionByReward -v

# Verify CLI arguments work
python scripts/train_gflownet.py --help | grep -E "(entropy_weight|log_z_lr_multiplier|loss_type)"
```

- [x] All new tests pass (12/12)
- [x] CLI arguments recognized
- [x] Default config updated

---

### Step 1: STB Validation Run (10K steps) ⏳ PENDING

**Objective**: Validate that Sub-Trajectory Balance loss produces stable training curves.

**Run Name**: `phase3b-stb-validation-10k`

```bash
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.01 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-validation/ \
    --run_name phase3b-stb-validation-10k \
    --wandb \
    --seed 42
```

**Success Criteria**:
- [ ] Loss stays bounded (< 100 throughout training)
- [ ] Loss curve stable or decreasing (no explosion)
- [ ] Mean reward increasing
- [ ] AA diversity ≥ 15/20 at final checkpoint
- [ ] 100% unique samples in batch

---

### Step 2: Entropy Weight Sweep ⏳ PENDING

**Objective**: Find optimal entropy regularization weight.

| Run Name | entropy_weight | Expected Effect |
|----------|----------------|-----------------|
| `phase3b-entropy-0.00-10k` | 0.00 | Baseline (no regularization) |
| `phase3b-entropy-0.01-10k` | 0.01 | Light regularization (default) |
| `phase3b-entropy-0.05-10k` | 0.05 | Medium regularization |
| `phase3b-entropy-0.10-10k` | 0.10 | Strong regularization |

---

### Step 3: Compare TB vs STB ⏳ PENDING

**Objective**: Confirm STB produces more stable curves than TB.

| Run Name | loss_type | Expected |
|----------|-----------|----------|
| `phase3b-tb-baseline-10k` | trajectory_balance | Loss may explode |
| `phase3b-stb-baseline-10k` | sub_trajectory_balance | Stable loss |

---

## Sequential Execution Command (Nohup-able)

**Full validation sweep** - Run all experiments sequentially:

```bash
nohup bash -c '
echo "=== Phase 3b Validation Runs ===" && \
echo "Started: $(date)" && \

# Run 1: STB Validation (main validation)
echo ">>> Run 1/6: phase3b-stb-validation-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.01 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-validation/ \
    --run_name phase3b-stb-validation-10k \
    --wandb \
    --seed 42 && \

# Run 2: Entropy weight = 0.00 (no regularization)
echo ">>> Run 2/6: phase3b-entropy-0.00-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.00 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-entropy-0.00/ \
    --run_name phase3b-entropy-0.00-10k \
    --wandb \
    --seed 42 && \

# Run 3: Entropy weight = 0.05 (medium)
echo ">>> Run 3/6: phase3b-entropy-0.05-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.05 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-entropy-0.05/ \
    --run_name phase3b-entropy-0.05-10k \
    --wandb \
    --seed 42 && \

# Run 4: Entropy weight = 0.10 (strong)
echo ">>> Run 4/6: phase3b-entropy-0.10-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.10 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-entropy-0.10/ \
    --run_name phase3b-entropy-0.10-10k \
    --wandb \
    --seed 42 && \

# Run 5: TB baseline (for comparison - expect loss explosion)
echo ">>> Run 5/6: phase3b-tb-baseline-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type trajectory_balance \
    --entropy_weight 0.01 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-tb-baseline/ \
    --run_name phase3b-tb-baseline-10k \
    --wandb \
    --seed 42 && \

# Run 6: STB with higher log_Z LR (10x) for comparison
echo ">>> Run 6/6: phase3b-stb-logz10x-10k" && \
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.01 \
    --log_z_lr_multiplier 10.0 \
    --output_dir checkpoints/gflownet/phase3b-stb-logz10x/ \
    --run_name phase3b-stb-logz10x-10k \
    --wandb \
    --seed 42 && \

echo "=== All runs completed ===" && \
echo "Finished: $(date)" && \
/home/ubuntu/bin/stopinstance
' > logs/phase3b-validation-$(date +%Y%m%d_%H%M%S).log 2>&1 &
```

**Expected Runtime**: ~18 hours total (~3 hours per run × 6 runs)

**Monitor Progress**:
```bash
# Watch log file
tail -f logs/phase3b-validation-*.log

# Check W&B dashboard
# https://wandb.ai/ewijaya/gflownet-peptide
```

---

## Quick Single Run Command

For testing a single configuration:

```bash
# Quick validation (STB + entropy)
python scripts/train_gflownet.py \
    --reward_type improved \
    --n_steps 10000 \
    --loss_type sub_trajectory_balance \
    --entropy_weight 0.01 \
    --log_z_lr_multiplier 3.0 \
    --output_dir checkpoints/gflownet/phase3b-validation/ \
    --run_name phase3b-stb-validation-10k \
    --wandb \
    --seed 42
```

---

## Post-Training Analysis Commands

### Compare Checkpoints

```bash
python -c "
import torch
from gflownet_peptide.models.forward_policy import ForwardPolicy
from collections import Counter

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

for name in ['best', 'final']:
    path = f'checkpoints/gflownet/phase3b-validation/phase3b-stb-validation-10k_{name}.pt'
    ckpt = torch.load(path, map_location=device)

    policy = ForwardPolicy(vocab_size=23, d_model=256, n_layers=4, n_heads=8, dim_feedforward=1024).to(device)
    policy.load_state_dict(ckpt['forward_policy_state_dict'])
    policy.eval()

    with torch.no_grad():
        seqs, _ = policy.sample_sequence(batch_size=100, max_length=30, min_length=10, device=device)

    unique = len(set(seqs))
    all_aa = set(''.join(seqs))

    print(f'{name}: unique={unique}/100, AA_diversity={len(all_aa)}/20')
    print(f'  Sample: {seqs[0]}')
    print(f'  Step: {ckpt[\"step\"]}, best_reward: {ckpt.get(\"best_reward\", \"N/A\")}')
"
```

### Check W&B Metrics

```bash
python -c "
import wandb
api = wandb.Api()

# List recent runs
runs = api.runs('ewijaya/gflownet-peptide', filters={'display_name': {'$regex': 'phase3b'}})
for run in runs[:10]:
    print(f'{run.id} | {run.name} | {run.state}')
"
```

---

## Success Criteria (Phase Gate Review)

| ID | Criterion | Target | Verification |
|----|-----------|--------|--------------|
| SC1 | Loss stable | No explosion (< 100) | W&B loss curve |
| SC2 | Loss bounded | Stays < 100 throughout | max(train/loss) |
| SC3 | Best checkpoint by reward | Highest mean_reward | Compare checkpoints |
| SC4 | Diverse samples | ≥ 15/20 amino acids | Sample analysis |
| SC5 | Unique samples | 100% unique in batch | eval/unique_ratio |
| SC6 | Entropy tracked | mean_entropy in W&B | W&B metrics |
| SC7 | log_pf bounded | > -50 average | train/mean_log_pf |
| SC8 | Tests pass | All 135 tests green | pytest |
| SC9 | Backward compatible | Old checkpoints load | Test loading |
| SC10 | Publishable curve | Monotonic or stable | Visual inspection |

---

## Files Modified This Session

| File | Action |
|------|--------|
| `gflownet_peptide/training/trainer.py` | Added best_reward tracking, checkpoint by reward |
| `gflownet_peptide/training/loss.py` | Added entropy_weight to TB and STB |
| `scripts/train_gflownet.py` | Added --entropy_weight, --log_z_lr_multiplier, --loss_type |
| `configs/default.yaml` | Changed defaults: STB, entropy_weight=0.01, log_z_lr=3.0 |
| `tests/test_trainer.py` | Added TestCheckpointSelectionByReward (4 tests) |
| `tests/test_loss.py` | Added TestEntropyRegularization (8 tests) |
| `docs/TODO-2025-12-27-1400.md` | Created |

---

## Key Configuration Changes

| Parameter | Before | After | Rationale |
|-----------|--------|-------|-----------|
| `loss_type` | `trajectory_balance` | `sub_trajectory_balance` | Stable loss curves |
| `log_z_lr_multiplier` | 10.0 | 3.0 | Reduce oscillation |
| `entropy_weight` | (none) | 0.01 | Prevent mode collapse |
| `lambda_sub` | (none) | 0.9 | STB decay factor |
| Checkpoint selection | by loss | by reward | "Best" = highest reward |

---

## Rollback Commands

If issues arise:

```bash
# Disable entropy regularization
python scripts/train_gflownet.py --entropy_weight 0.0 ...

# Revert to TB loss
python scripts/train_gflownet.py --loss_type trajectory_balance ...

# Revert to original log_Z LR
python scripts/train_gflownet.py --log_z_lr_multiplier 10.0 ...
```

---

## W&B Dashboard

- Project: https://wandb.ai/ewijaya/gflownet-peptide
- Phase 3 runs: Filter by `phase3b-*`

---

## Next Steps (After Phase 3b Validation)

1. **Analyze validation runs** - Determine best entropy_weight and confirm STB stability
2. **Full training (100K steps)** - Use best configuration
3. **Phase 4** - Evaluation & GRPO Comparison
