# GRPO-D with Improved Reward (Entropy Gate)
# ==========================================
# Phase 0b Configuration
# Uses improved reward with entropy gate to prevent reward hacking
# from repetitive sequences like QQQQQQQ

# Model Configuration
model_name: "littleworth/protgpt2-distilled-medium"
hidden_dim: 512

# Peptide Constraints
min_length: 10
max_length: 30
amino_acids: "ACDEFGHIKLMNPQRSTVWY"

# GRPO Hyperparameters
learning_rate: 3.0e-4
batch_size: 16
num_generations: 8
beta: 0.04
max_grad_norm: 1.0

# Diversity Configuration (GRPO-D)
diversity_weight: 0.15
diversity_weight_aa: 0.7
diversity_weight_seq: 0.3
use_sequence_diversity: true

# Training Configuration
total_iterations: 1000
buffer_size: 500
min_buffer_size: 16
save_interval: 200
eval_interval: 50

# Generation Parameters
temperature: 1.0
top_p: 0.95
repetition_penalty: 1.0

# ESM-2 Model
esm_model: "esm2_t6_8M_UR50D"

# ===========================================
# IMPROVED REWARD CONFIGURATION
# ===========================================

# Use improved reward instead of ESM-2 pseudo-likelihood
reward_type: "improved"

# Entropy Gate Parameters
# - entropy_threshold: Minimum normalized entropy (0-1 scale)
#   Values below this get penalized. 0.5 = 50% of max entropy
# - entropy_sharpness: Sigmoid slope. Higher = sharper cutoff
entropy_threshold: 0.5
entropy_sharpness: 10.0

# Length Gate Parameters
# - length_sharpness: Sigmoid slope for length penalty
length_sharpness: 0.5

# Embedding Parameters
# - embedding_temperature: Sigmoid temp for naturalness score
embedding_temperature: 10.0

# ===========================================
# OUTPUT PATHS
# ===========================================

checkpoint_dir: "checkpoints/grpo"
results_dir: "results/grpo"

# W&B Configuration
wandb_project: "gflownet-peptide"
wandb_entity: "ewijaya"
